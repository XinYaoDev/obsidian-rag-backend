package com.agent.rag.ragbackend.service;


import com.agent.rag.ragbackend.config.ProviderConfig;
import com.agent.rag.ragbackend.dto.request.ChatRequest;
import com.agent.rag.ragbackend.dto.request.OpenAiRequest;
import com.agent.rag.ragbackend.dto.response.OpenAiResponse;
import com.agent.rag.ragbackend.dto.response.RagResponse;
import lombok.extern.slf4j.Slf4j;
import org.springframework.http.HttpEntity;
import org.springframework.http.HttpHeaders;
import org.springframework.http.MediaType;
import org.springframework.http.ResponseEntity;
import org.springframework.stereotype.Service;
import org.springframework.web.client.HttpClientErrorException;
import org.springframework.web.client.HttpServerErrorException;

import org.springframework.web.client.RestTemplate;

import java.util.ArrayList;
import java.util.Collections;
import java.util.List;

@Slf4j
@Service
public class LlmService {

    private final RestTemplate restTemplate = new RestTemplate();

    public RagResponse<String> chat(String providerCode, String model, String apiKey, String question,List<ChatRequest.HistoryMessage> history) {
        ProviderConfig config = ProviderConfig.fromCode(providerCode);
        String apiUrl = config.getBaseUrl() + "/chat/completions";

        // ... (Header å’Œ Body çš„æ„é€ é€»è¾‘ä¿æŒä¸å˜) ...
        HttpHeaders headers = new HttpHeaders();
        headers.setContentType(MediaType.APPLICATION_JSON);
        headers.setBearerAuth(apiKey);

        // ğŸ”¥ æ„é€  Promptï¼šåŠ å…¥ System Prompt (ç³»ç»ŸæŒ‡ä»¤)
        List<OpenAiRequest.Message> messages = new ArrayList<>();

        // 1. ç³»ç»ŸæŒ‡ä»¤ï¼šå¼ºåˆ¶è¦æ±‚ç´§å‡‘æ’ç‰ˆ
        messages.add(OpenAiRequest.Message.builder()
                .role("system")
                .content("ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†åº“åŠ©æ‰‹ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚" +
                        "ã€é‡è¦æ ¼å¼è¦æ±‚ã€‘ï¼šåœ¨ç”Ÿæˆ Markdown åˆ—è¡¨ï¼ˆæ— åºåˆ—è¡¨æˆ–æœ‰åºåˆ—è¡¨ï¼‰æ—¶ï¼Œ" +
                        "è¯·åŠ¡å¿…ä¿æŒç´§å‡‘ï¼Œ**åˆ—è¡¨é¡¹ä¹‹é—´ä¸è¦æ’å…¥ç©ºè¡Œ**ã€‚" +
                        "ä¸è¦è¾“å‡ºæ¾æ•£åˆ—è¡¨ï¼Œä»¥ç¡®ä¿åœ¨å®¢æˆ·ç«¯æ¸²æŸ“æ—¶æ’ç‰ˆæ•´æ´ã€‚")
                .build());

        // 2. ã€ç¬¬äºŒå±‚ã€‘æ’å…¥å†å²è®°å½• (è®©æ¨¡å‹çŸ¥é“ä¸Šä¸‹æ–‡)
        if (history != null && !history.isEmpty()) {
            // é™åˆ¶ä¸€ä¸‹å†å²è®°å½•é•¿åº¦ï¼ˆæ¯”å¦‚åªä¿ç•™æœ€è¿‘ 10 æ¡ï¼‰ï¼Œé˜²æ­¢ Token çˆ†ç‚¸
            int start = Math.max(0, history.size() - 10);
            for (int i = start; i < history.size(); i++) {
                ChatRequest.HistoryMessage hist = history.get(i);
                messages.add(OpenAiRequest.Message.builder()
                        .role(hist.getRole())
                        .content(hist.getContent())
                        .build());
            }
        }

        // 3. ã€ç¬¬ä¸‰å±‚ã€‘å½“å‰é—®é¢˜
        messages.add(OpenAiRequest.Message.builder()
                .role("user")
                .content(question)
                .build());

        OpenAiRequest requestBody = OpenAiRequest.builder()
                .model(model != null && !model.isEmpty() ? model : config.getDefaultModel())
                .messages(messages) // ä½¿ç”¨æ–°çš„ messages åˆ—è¡¨
                .stream(false)
                .build();


        try {
            HttpEntity<OpenAiRequest> entity = new HttpEntity<>(requestBody, headers);
            ResponseEntity<OpenAiResponse> response = restTemplate.postForEntity(apiUrl, entity, OpenAiResponse.class);

            if (response.getBody() != null && !response.getBody().getChoices().isEmpty()) {
                String content = response.getBody().getChoices().get(0).getMessage().getContent();
                // âœ… æˆåŠŸè¿”å›ç»“æ„ä½“
                return RagResponse.success(content);
            }
            return RagResponse.error("âš ï¸ æ¨¡å‹è¿”å›äº†ç©ºå†…å®¹");

        } catch (HttpClientErrorException e) {
            log.error("LLM Client Error: {}", e.getMessage());
            String msg = switch (e.getStatusCode().value()) {
                case 401 -> "ğŸš« é‰´æƒå¤±è´¥ï¼šè¯·æ£€æŸ¥ API Key";
                case 404 -> "â“ æ¨¡å‹ä¸å­˜åœ¨ï¼š" + requestBody.getModel();
                case 429 -> "â³ ä½™é¢ä¸è¶³æˆ–è¯·æ±‚è¿‡å¿«";
                default -> "âŒ å®¢æˆ·ç«¯é”™è¯¯: " + e.getStatusCode();
            };
            // âœ… å¤±è´¥è¿”å›ç»“æ„ä½“
            return RagResponse.error(msg);

        } catch (HttpServerErrorException e) {
            log.error("LLM Server Error: {}", e.getMessage());
            return RagResponse.error("ğŸ’¥ æœåŠ¡å•† (" + providerCode + ") å´©æºƒï¼Œè¯·ç¨åé‡è¯•");

        } catch (Exception e) {
            log.error("LLM Unknown Error", e);
            return RagResponse.error("ğŸ ç³»ç»ŸæœªçŸ¥é”™è¯¯: " + e.getMessage());
        }
    }
}
