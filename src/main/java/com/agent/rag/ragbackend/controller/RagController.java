package com.agent.rag.ragbackend.controller;

import com.agent.rag.ragbackend.dto.request.ChatRequest;
import com.agent.rag.ragbackend.dto.request.LlmCompletionRequest;
import com.agent.rag.ragbackend.dto.request.SyncRequest;
import com.agent.rag.ragbackend.dto.response.RagResponse;
import com.agent.rag.ragbackend.service.LlmService;
import com.fasterxml.jackson.core.JsonProcessingException;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.http.MediaType;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.*;
import org.springframework.web.servlet.mvc.method.annotation.SseEmitter;

import java.util.Collections;
import java.util.List;
import java.util.Optional;
import java.util.concurrent.CompletableFuture;
import java.util.stream.Collectors;

@RestController
@RequestMapping("/api/rag")
@CrossOrigin(origins = "*")
@Slf4j
@RequiredArgsConstructor
public class RagController {

    private final LlmService llmService;

    @PostMapping("/sync")
    public ResponseEntity<String> syncFile(@RequestBody SyncRequest request) {
        log.info("æ”¶åˆ° Obsidian åŒæ­¥è¯·æ±‚ - æ–‡ä»¶: {}, è·¯å¾„: {}", request.getTitle(), request.getPath());
        // service.process(request);
        return ResponseEntity.ok("Sync Success");
    }

    /**
     * æ™®é€šå¯¹è¯æ¥å£ (ç­‰å¾…å…¨éƒ¨ç”Ÿæˆå®Œä¸€æ¬¡æ€§è¿”å›)
     */
    @PostMapping("/chat")
    public ResponseEntity<RagResponse<Object>> chat(
            @RequestBody ChatRequest request,
            @RequestHeader(value = "X-API-KEY", required = false) String apiKey
    ) throws JsonProcessingException {
        // 1. è½¬æ¢è¯·æ±‚
        LlmCompletionRequest llmRequest = convertToLlmRequest(request, apiKey);

        log.info("æ”¶åˆ°æ™®é€šå¯¹è¯è¯·æ±‚ - æ¨¡å‹: {}, æ·±åº¦æ€è€ƒ: {}", request.getModel(), request.getEnableDeepThinking());

        // 2. è°ƒç”¨ Service
        RagResponse<Object> result = llmService.chat(llmRequest);

        return ResponseEntity.ok(result);
    }

    /**
     * âœ… æ–°å¢ï¼šæµå¼å¯¹è¯æ¥å£ (SSE)
     * å“åº”ç±»å‹å¿…é¡»æ˜¯ text/event-stream
     */
    @PostMapping(value = "/chat/stream", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    public SseEmitter streamChat(
            @RequestBody ChatRequest request,
            @RequestHeader(value = "X-API-KEY", required = false) String apiKey
    ) {
        log.info("æ”¶åˆ°æµå¼å¯¹è¯è¯·æ±‚ (SSE) - æ¨¡å‹: {}, æ·±åº¦æ€è€ƒ: {}", request.getModel(), request.getEnableDeepThinking());

        // 1. åˆ›å»º SseEmitter (0L è¡¨ç¤ºæ°¸ä¸è¶…æ—¶ï¼Œé˜²æ­¢ AI å›ç­”æ—¶é—´è¿‡é•¿å¯¼è‡´è¿æ¥æ–­å¼€)
        SseEmitter emitter = new SseEmitter(0L);

        // 2. è½¬æ¢è¯·æ±‚å¯¹è±¡
        LlmCompletionRequest llmRequest = convertToLlmRequest(request, apiKey);

        // 3. å¼‚æ­¥è°ƒç”¨ Serviceï¼Œé˜²æ­¢é˜»å¡ä¸»çº¿ç¨‹
        CompletableFuture.runAsync(() -> {
            try {
                // æ³¨æ„ï¼šä½ éœ€è¦ç¡®ä¿ LlmService ä¸­å·²ç»å®ç°äº†è¿™ä¸ª streamChat æ–¹æ³•
                llmService.streamChat(llmRequest, emitter);
            } catch (Exception e) {
                log.error("æµå¼ç”Ÿæˆå¼‚å¸¸", e);
                emitter.completeWithError(e);
            }
        });

        // 4. ç›´æ¥è¿”å› emitterï¼Œå»ºç«‹è¿æ¥
        return emitter;
    }

    /**
     * ğŸ§ª ä¸“ç”¨æµ‹è¯•æ¥å£ï¼šæ¨¡æ‹Ÿæµå¼è¾“å‡º (ä¸è°ƒç”¨å¤§æ¨¡å‹)
     * ç”¨é€”ï¼šæµ‹è¯•å‰ç«¯æ˜¯å¦èƒ½æ­£ç¡®æ¥æ”¶ SSE æµï¼Œä»¥åŠä¸­é—´ä»¶(Nginx)æ˜¯å¦æœ‰ç¼“å†²é—®é¢˜
     * è¯·æ±‚æ–¹å¼ï¼šPOST /api/rag/test/stream
     */
    @PostMapping(value = "/test/stream", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    public SseEmitter testStream(@RequestBody ChatRequest request) { // ä¿æŒå’Œæ­£å¼æ¥å£ä¸€æ ·çš„å‚æ•°ç»“æ„ï¼Œæ–¹ä¾¿å‰ç«¯ç›´æ¥åˆ‡æ¢
        log.info("ğŸ§ª æ”¶åˆ°æµ‹è¯•æµè¯·æ±‚ï¼Œå¼€å§‹æ¨¡æ‹Ÿæ•°æ®...");

        // 1. åˆ›å»º Emitter (æ°¸ä¸è¶…æ—¶)
        SseEmitter emitter = new SseEmitter(0L);

        // 2. å¼‚æ­¥æ‰§è¡Œæ¨¡æ‹Ÿä»»åŠ¡
        CompletableFuture.runAsync(() -> {
            try {
                // === é˜¶æ®µä¸€ï¼šæ¨¡æ‹Ÿæ·±åº¦æ€è€ƒ (Thinking) ===
                String[] thinkingSteps = {
                        "æ­£åœ¨æ£€ç´¢çŸ¥è¯†åº“...",
                        "å‘ç°ç›¸å…³æ–‡æ¡£: 'Javaå¹¶å‘ç¼–ç¨‹.pdf'...",
                        "æ­£åœ¨è§„åˆ’å›ç­”é€»è¾‘...",
                        "æ€è€ƒå®Œæ¯•ï¼Œå‡†å¤‡ç”Ÿæˆç­”æ¡ˆã€‚"
                };

                for (String step : thinkingSteps) {
                    // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
                    Thread.sleep(800);
                    // å‘é€ thinking äº‹ä»¶
                    emitter.send(SseEmitter.event().name("thinking").data(step));
                    log.info("ğŸ§ª æ¨é€æ€è€ƒ: {}", step);
                }

                // === é˜¶æ®µäºŒï¼šæ¨¡æ‹Ÿæ‰“å­—æœºå›ç­” (Answer) ===
                String mockAnswer = "ä½ å¥½ï¼è¿™æ˜¯ä¸€ä¸ªç”¨äºæµ‹è¯• **æµå¼è¾“å‡º (SSE)** çš„æ¨¡æ‹Ÿå›å¤ã€‚\n\n" +
                        "å¦‚æœä½ èƒ½çœ‹åˆ°è¿™æ®µæ–‡å­—åƒæ‰“å­—æœºä¸€æ ·é€å­—å‡ºç°ï¼Œè¯´æ˜ä½ çš„ï¼š\n" +
                        "1. å‰ç«¯ fetch è¯»å–é€»è¾‘æ˜¯æ­£ç¡®çš„ã€‚\n" +
                        "2. åç«¯ SseEmitter é…ç½®æ˜¯æ­£ç¡®çš„ã€‚\n" +
                        "3. Nginx/ç½‘å…³æ²¡æœ‰æ‹¦æˆªç¼“å†²æµæ•°æ®ã€‚\n\n" +
                        "æµ‹è¯•ç»“æŸã€‚ğŸš€";

                // å°†ç­”æ¡ˆæ‹†åˆ†ä¸ºå­—ç¬¦ï¼Œæ¨¡æ‹Ÿ token ç”Ÿæˆ
                for (char c : mockAnswer.toCharArray()) {
                    Thread.sleep(50); // æ¯ä¸ªå­—é—´éš” 50ms
                    emitter.send(SseEmitter.event().name("answer").data(String.valueOf(c)));
                }

                // === ç»“æŸ ===
                log.info("ğŸ§ª æµ‹è¯•æµç»“æŸ");
                emitter.complete();

            } catch (Exception e) {
                log.error("ğŸ§ª æµ‹è¯•æµå¼‚å¸¸", e);
                emitter.completeWithError(e);
            }
        });

        return emitter;
    }

    /**
     * ğŸ› ï¸ è¾…åŠ©æ–¹æ³•ï¼šå°†å‰ç«¯ ChatRequest è½¬æ¢ä¸ºåç«¯ LlmCompletionRequest
     * æå–å‡ºæ¥å¤ç”¨ï¼Œé¿å…ä»£ç é‡å¤
     */
    private LlmCompletionRequest convertToLlmRequest(ChatRequest request, String apiKey) {
        // å®‰å…¨åœ°å¤„ç†å†å²è®°å½•è½¬æ¢
        List<LlmCompletionRequest.LlmMessage> llmHistory = Optional.ofNullable(request.getHistory())
                .orElse(Collections.emptyList())
                .stream()
                .map(msg -> LlmCompletionRequest.LlmMessage.builder()
                        .role(msg.getRole())
                        .content(msg.getContent())
                        .build())
                .collect(Collectors.toList());

        return LlmCompletionRequest.builder()
                .provider(request.getProvider())
                .model(request.getModel())
                .apiKey(apiKey)
                .prompt(request.getQuestion())
                .context(llmHistory)
                .enableDeepThinking(request.getEnableDeepThinking())
                .build();
    }
}